<!DOCTYPE html>
<html lang="en">
<head prefix="og: http://ogp.me/ns#">
  <meta charset="utf-8">

  <title>OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.</title>

  <meta http-equiv="X-UA-Compatible" content="IE=8; IE=9; IE=Edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta name="robots" content="noodp" />
  <meta name="keywords" content="OpenCV 3.3 Supports Several Deep Learning Frameworks" />
  <meta name="description" content="OpenCV 3.3 Supports Several Deep Learning Frameworks" />

  <!-- Custom config og:image -->


  <!-- Open Graph -->
<meta name="description" content="OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:type" content="apps">
<meta property="og:title" content="OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:url" content="https://gmagon.com/blog/2017/08/22/opencv-33-supports-several-deep-learning-frameworks/index.html">
<meta property="og:site_name" content="OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:description" content="OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://img1.tuicool.com/jaMFjyR.jpg!web">
<meta property="og:image" content="http://img1.tuicool.com/IbqeMfm.jpg!web">
<meta property="og:image" content="http://img0.tuicool.com/zYry2qi.jpg!web">
<meta property="og:image" content="http://img0.tuicool.com/nI3eiiF.jpg!web">
<meta property="og:image" content="http://img0.tuicool.com/6jyaeyu.jpg!web">
<meta property="og:updated_time" content="2017-08-22T12:00:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.">
<meta name="twitter:description" content="OpenCV 3.3 Supports Several Deep Learning Frameworks - Gmagon Software - handy and professional Mac apps.">
<meta name="twitter:image" content="http://img1.tuicool.com/jaMFjyR.jpg!web">
<meta name="twitter:site" content="gmagonshare">
<meta property="fb:admins" content="432634277117208">
<meat name="twitter:url" content="https://gmagon.com/blog/2017/08/22/opencv-33-supports-several-deep-learning-frameworks/index.html">



  <!-- algolia_config -->
  
  
  <!-- Canonical links -->
  <link rel="canonical" href="https://gmagon.com/blog/2017/08/22/opencv-33-supports-several-deep-learning-frameworks/index.html">

  <!-- Alternative links -->
  

  <!-- Icon -->
  <link rel="apple-touch-icon" sizes="57x57" href="/icon/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icon/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icon/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icon/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icon/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icon/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icon/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icon/apple-touch-icon-152x152.png">
  <link rel="icon" type="image/png" href="/icon/favicon-196x196.png" sizes="196x196">
  <link rel="icon" type="image/png" href="/icon/favicon-160x160.png" sizes="160x160">
  <link rel="icon" type="image/png" href="/icon/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/icon/favicon-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="/icon/favicon-32x32.png" sizes="32x32">
  <meta name="msapplication-TileColor" content="#2f83cd">
  <meta name="msapplication-TileImage" content="/icon/mstile-144x144.png">

  <!-- CSS -->
  <link rel="stylesheet" href="/build/css/navy-9c7f2a6219.css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/asset/styles/global.css">
  
  <!-- jQuery -->
  <script src="/js/jquery/jquery-3.2.1.min.js"></script>
<script src="/js/jquery/jquery-migrate-1.4.1.min.js"></script>



  <!-- ForPostLayout -->
  
    
    
  
  <!-- endForPostLayout -->

  <!-- RSS -->
  <link rel="alternate" href="/atom.xml" title="Gmagon Software - handy and professional Mac apps.">

  <!-- algolia_search -->
  <script src="/assets/algolia/algoliasearchLite.min.js" async></script>

  <!-- Utils -->
<script src="/js/utils.js"></script>
</head>

<body>
  <div id="container">
    <header id="header">
  <div class="wrapper">
    <div id="header-inner" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Gmagon Software - handy and professional Mac apps.</a>
        <span>gmagon </span>
      </h1>
      <nav id="main-nav">
        <a href="/" class="main-nav-link ">Home</a><a href="/products/" class="main-nav-link ">Products</a><a href="/guide/" class="main-nav-link ">Guide</a><a href="/support/" class="main-nav-link ">Support</a><a href="/blog/" class="main-nav-link ">Blog</a>
        <div id="search-input-wrap">
          <a href="/search/" class="text-decoration-none">
            <div id="search-input-icon">
              <i class="fa fa-search"></i>
            </div>
          </a>
        </div>
      </nav>
      <div id="lang-select-wrap">
        <label id="lang-select-label"><i class="fa fa-globe"></i><span>English</span></label>
        <select id="lang-select" data-canonical="">
          
            <option value="en" selected>English</option>
          
        </select>
      </div>
      <a id="mobile-nav-toggle">
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
      </a>
    </div>
  </div>  
</header>
<div class="hide-wrap-head-top"></div>

    <div class="class-content-wrap">
  <div class="inner">
    <div class="inner-wrap fill-bunting font-e3">
      <h2 id="banner-title"> OpenCV 3.3 Supports Several Deep Learning Frameworks </h2>
      <div id="banner-start">
        <a class="btn btn-static-secondary btn-shadow" href="https://gitter.im/Gmagon/support" ttarget="_blank" rel="nofollow me noopener noreferrer" >Need help?</a>
      </div>
    </div>
  </div>
</div>

<div class="class-content-wrap">
  <div class="wrapper">
    <div class="inner">
      <article class="article-container" itemscope itemtype="http://schema.org/Article">
        <div class="article-inner">
          <div class="article">
          <div class="hide-wrap-head-top"></div>
<article class="article post" itemscope itemtype="http://schema.org/Article">
  <header class="article-header">
    
      <h1 class="article-title" itemprop="name">OpenCV 3.3 Supports Several Deep Learning Frameworks</h1>
    
    <a href="/blog/2017/08/22/opencv-33-supports-several-deep-learning-frameworks/" class="article-date"><time datetime="2017-08-22T00:00:00.000Z">2017-08-22</time></a>
  </header>
  <div class="article-content" itemprop="articleBody">
    <p><img src="http://img1.tuicool.com/jaMFjyR.jpg!web" alt=""></p>
<p>Two weeks ago OpenCV 3.3 was officially released, bringing with it a highly improved deep learning (dnn) module. This module now supports a number of deep learning frameworks, including Caffe, TensorFlow, and Torch/PyTorch.</p>
<p>Furthermore, this API for using_pre-trained deep learning models_is compatible with_both_the C++ API and the Python bindings, making it_dead simple_to:</p>
<ol>
<li>Load a model from disk.</li>
<li>Pre-process an input image.</li>
<li>Pass the image through the network and obtain the output classifications.</li>
</ol>
<p>While we cannot_train_deep learning models using OpenCV (nor should we), this_does_allow us to take our models trained using dedicated deep learning libraries/tools and then efficiently use them directly inside our OpenCV scripts.</p>
<p>In the remainder of this blog post I’ll demonstrate the fundamentals of how to take a pre-trained deep learning network on the ImageNet dataset and apply it to input images.</p>
<p>To learn more about deep learning with OpenCV,<em>just keep reading.</em></p>
<p>Looking for the source code to this post?</p>
<p>Jump right to the downloads section.</p>
<h2 id="Deep-Learning-with-OpenCV"><a href="#Deep-Learning-with-OpenCV" class="headerlink" title="Deep Learning with OpenCV"></a>Deep Learning with OpenCV</h2><p>In the first part of this post, we’ll discuss the OpenCV 3.3 release and the overhauleddnnmodule.</p>
<p>We’ll then write a Python script that will use OpenCV and GoogleLeNet (pre-trained on ImageNet) to classify images.</p>
<p>Finally, we’ll explore the results of our classifications.</p>
<h3 id="Deep-Learning-inside-OpenCV-3-3"><a href="#Deep-Learning-inside-OpenCV-3-3" class="headerlink" title="Deep Learning inside OpenCV 3.3"></a>Deep Learning inside OpenCV 3.3</h3><p>The<a href="https://github.com/opencv/opencv/tree/master/modules/dnn">dnn module</a>of OpenCV has been part of theopencv_contribrepository since version v3.1. Now in OpenCV 3.3 it is included in the main repository.</p>
<p>Why should you care?</p>
<p>Deep Learning is a fast growing domain of Machine Learning and if you’re working in the field of computer vision/image processing already (or getting up to speed), it’s a crucial area to explore.</p>
<p>With OpenCV 3.3, we can utilize pre-trained networks with popular deep learning frameworks. The fact that they are_pre-trained_implies that we don’t need to spend many hours training the network — rather we can complete a forward pass and utilize the output to make a decision within our application.</p>
<p>OpenCV does not (and does not intend to be) to be a tool for training networks — there are already great frameworks available for that purpose. Since a network (such as a CNN) can be used as a classifier, it makes logical sense that OpenCV has a Deep Learning module that we can leverage easily within the OpenCV ecosystem.</p>
<p>Popular network architectures compatible with OpenCV 3.3 include:</p>
<ul>
<li>GoogleLeNet (used in this blog post)</li>
<li>AlexNet</li>
<li>SqueezeNet</li>
<li>VGGNet (and associated flavors)</li>
<li>ResNet</li>
</ul>
<p>The release notes for this module are available on the OpenCV repository<a href="https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV">page</a>.</p>
<p>Rynikov Alexander, the main contributor for this module, has ambitious plans for this module so be sure to stay on the lookout and read his<a href="https://habrahabr.ru/company/intel/blog/333612/">release notes</a>(in Russian, so make sure you have Google Translation enabled in your browser if Russian is not your native language).</p>
<p>It’s my opinion that thednnmodule will have a big impact on the OpenCV community, so let’s get the word out.</p>
<h4 id="Configure-your-machine-with-OpenCV-3-3"><a href="#Configure-your-machine-with-OpenCV-3-3" class="headerlink" title="Configure your machine with OpenCV 3.3"></a>Configure your machine with OpenCV 3.3</h4><p>Installing OpenCV 3.3 is on par with installing other versions. The same install tutorials can be utilized — just make sure you download and use the correct release.</p>
<p>Simply follow these instructions forMacOS orUbuntu while making sure to use the<a href="https://github.com/opencv/opencv/releases/tag/3.3.0">opencv</a>and<a href="https://github.com/opencv/opencv_contrib/releases/tag/3.3.0">opencv_contrib</a>releases for OpenCV 3.3. If you opt for theMacOS + homebrew install instructions, be sure to use the–HEADswitch (among the others mentioned) to get the bleeding edge version of OpenCV.</p>
<p>If you’re using virtual environments (<strong>highly recommended</strong>), you can easily install OpenCV 3.3 alongside a previous version. Just create a brand new virtual environment (and name it appropriately) as you follow the tutorial corresponding to your system.</p>
<h4 id="OpenCV-deep-learning-functions-and-frameworks"><a href="#OpenCV-deep-learning-functions-and-frameworks" class="headerlink" title="OpenCV deep learning functions and frameworks"></a>OpenCV deep learning functions and frameworks</h4><p>OpenCV 3.3 supports the<a href="http://caffe.berkeleyvision.org/">Caffe</a>,<a href="https://www.tensorflow.org/">TensorFlow</a>, and<a href="http://torch.ch/">Torch</a>/<a href="http://pytorch.org/">PyTorch</a>frameworks.</p>
<p><a href="https://keras.io/">Keras</a>is currently not supported (since Keras is actually a wrapper around backends such as TensorFlow and<a href="http://deeplearning.net/software/theano/">Theano</a>), although I imagine it’s only a matter of time until Keras is directly supported given the popularity of the deep learning library.</p>
<p>Using OpenCV 3.3 we can load images from disk using the following functions insidednn:</p>
<ul>
<li>cv2<br>.<br>dnn<br>.<br>blobFromImage</li>
<li>cv2<br>.<br>dnn<br>.<br>blobFromImages</li>
</ul>
<p>We can directly import models from various frameworks via the “create” methods:</p>
<ul>
<li>cv2<br>.<br>dnn<br>.<br>createCaffeImporter</li>
<li>cv2<br>.<br>dnn<br>.<br>createTensorFlowImporter</li>
<li>cv2<br>.<br>dnn<br>.<br>createTorchImporter</li>
</ul>
<p>Although I think it’s easier to simply use the “read” methods and load a serialized model from disk directly:</p>
<ul>
<li>cv2<br>.<br>dnn<br>.<br>readNetFromCaffe</li>
<li>cv2<br>.<br>dnn<br>.<br>readNetFromTensorFlow</li>
<li>cv2<br>.<br>dnn<br>.<br>readNetFromTorch</li>
<li>cv2<br>.<br>dnn<br>.<br>readhTorchBlob</li>
</ul>
<p>Once we have loaded a model from disk, the<code>.forward</code>method is used to forward-propagate our image and obtain the actual classification.</p>
<p>To learn how all these OpenCV deep learning pieces fit together, let’s move on to the next section.</p>
<h3 id="Classifying-images-using-deep-learning-and-OpenCV"><a href="#Classifying-images-using-deep-learning-and-OpenCV" class="headerlink" title="Classifying images using deep learning and OpenCV"></a>Classifying images using deep learning and OpenCV</h3><p>In this section, we’ll be creating a Python script that can be used to classify input images using OpenCV and GoogLeNet (pre-trained on ImageNet) using the Caffe framework.</p>
<p>The GoogLeNet architecture (now known as “Inception” after the novel micro-architecture) was introduced by Szegedy et al. in their 2014 paper,<a href="https://arxiv.org/abs/1409.4842"><em>Going deeper with convolutions</em></a>.</p>
<p>Other architectures are also supported with OpenCV 3.3 including AlexNet, ResNet, and SqueezeNet — we’ll be examining these architectures for deep learning with OpenCV in a future blog post.</p>
<p>In the meantime, let’s learn how we can load a pre-trained Caffe model and use it to classify an image using OpenCV.</p>
<p>To begin, open up a new file, name itdeep_learning_with_opencv.py, and insert the following code:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># </div><div class="line">import</div><div class="line"> the necessary packages</div><div class="line"></div><div class="line">import</div><div class="line"> numpy </div><div class="line">as</div><div class="line"> np</div><div class="line"></div><div class="line">import</div><div class="line"> argparse</div><div class="line"></div><div class="line">import</div><div class="line"> time</div><div class="line"></div><div class="line">import</div><div class="line"> cv2</div></pre></td></tr></table></figure>
<p>On<strong>Lines 2-5</strong>we import our necessary packages.</p>
<p>Then we parse command line arguments:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># construct the argument parse and parse the arguments</div><div class="line"></div><div class="line">ap = argparse.ArgumentParser()</div><div class="line">ap.add_argument(</div><div class="line">&quot;-i&quot;</div><div class="line">, </div><div class="line">&quot;--image&quot;</div><div class="line">, required=</div><div class="line">True</div><div class="line">,</div><div class="line"> help=</div><div class="line">&quot;path to input image&quot;</div><div class="line">)</div><div class="line">ap.add_argument(</div><div class="line">&quot;-p&quot;</div><div class="line">, </div><div class="line">&quot;--prototxt&quot;</div><div class="line">, required=</div><div class="line">True</div><div class="line">,</div><div class="line"> help=</div><div class="line">&quot;path to Caffe &apos;deploy&apos; prototxt file&quot;</div><div class="line">)</div><div class="line">ap.add_argument(</div><div class="line">&quot;-m&quot;</div><div class="line">, </div><div class="line">&quot;--model&quot;</div><div class="line">, required=</div><div class="line">True</div><div class="line">,</div><div class="line"> help=</div><div class="line">&quot;path to Caffe pre-trained model&quot;</div><div class="line">)</div><div class="line">ap.add_argument(</div><div class="line">&quot;-l&quot;</div><div class="line">, </div><div class="line">&quot;--labels&quot;</div><div class="line">, required=</div><div class="line">True</div><div class="line">,</div><div class="line"> help=</div><div class="line">&quot;path to ImageNet labels (i.e., syn-sets)&quot;</div><div class="line">)</div><div class="line">args = vars(ap.parse_args())</div></pre></td></tr></table></figure>
<p>On<strong>Line 8</strong>we create an argument parser followed by establishing four required command line arguments (<strong>Lines 9-16</strong>):</p>
<hr>
<p>  image<br>   : The path to the input image.</p>
<hr>
<p>  prototxt<br>   : The path to the Caffe “deploy” prototxt file.</p>
<hr>
<p>  model<br>   : The pre-trained Caffe model (i.e,. the network weights themselves).</p>
<hr>
<p>  labels<br>   : The path to ImageNet labels (i.e., “syn-sets”).</p>
<p>Now that we’ve established our arguments, we parse them and store them in a variable,args, for easy access later.</p>
<p>Let’s load the input image and class labels:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># load the input image from disk</div><div class="line">image</div><div class="line"> = cv2.imread(args[</div><div class="line">&quot;image&quot;</div><div class="line">])</div><div class="line"> </div><div class="line"></div><div class="line"># load the class labels from disk</div><div class="line">rows</div><div class="line"> = open(args[</div><div class="line">&quot;labels&quot;</div><div class="line">]).read().strip().split(</div><div class="line">&quot;\n&quot;</div><div class="line">)</div><div class="line"></div><div class="line">classes</div><div class="line"> = [r[r.find(</div><div class="line">&quot; &quot;</div><div class="line">) + </div><div class="line">1</div><div class="line">:].split(</div><div class="line">&quot;,&quot;</div><div class="line">)[</div><div class="line">0</div><div class="line">] for r in rows]</div></pre></td></tr></table></figure>
<p>On<strong>Line 20</strong>, we load theimagefrom disk viacv2.imread.</p>
<p>Let’s take a closer look at the class label data which we load on<strong>Lines 23 and 24</strong>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">n01440764</div><div class="line"> tench, Tinca tinca</div><div class="line">n01443537 goldfish, Carassius auratus</div><div class="line">n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias</div><div class="line">n01491361 tiger shark, Galeocerdo cuvieri</div><div class="line">n01494475 hammerhead, hammerhead shark</div><div class="line">n01496331 electric ray, crampfish, numbfish, torpedo</div><div class="line">n01498041 stingray</div><div class="line">...</div></pre></td></tr></table></figure>
<p>As you can see, we have a unique identifier followed by a space, some class labels, and a new-line. Parsing this file line-by-line is straightforward and efficient using Python.</p>
<p>First, we load the class labelrowsfrom disk into a list. To do this we strip whitespace from the beginning and end of each line while using the new-line (‘\n‘) as the row delimiter (<strong>Line 23</strong>). The result is a list of IDs and labels:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[&apos;n01440764 tench, Tinca tinca&apos;, &apos;n01443537 goldfish, Carassius auratus&apos;,</div><div class="line">&apos;n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias&apos;,</div><div class="line">&apos;n01491361 tiger shark, Galeocerdo cuvieri&apos;,</div><div class="line">&apos;n01494475 hammerhead, hammerhead shark&apos;,</div><div class="line">&apos;n01496331 electric ray, crampfish, numbfish, torpedo&apos;,</div><div class="line">&apos;n01498041 stingray&apos;, ...]</div></pre></td></tr></table></figure>
<p>Second, we use list comprehension to extract the relevant class labels fromrowsby looking for the space (‘ ‘) after the ID, followed by delimiting class labels with a comma (‘,‘). The result is simply a list of class labels:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[</div><div class="line">&apos;tench</div><div class="line">&apos;, </div><div class="line">&apos;goldfish</div><div class="line">&apos;, </div><div class="line">&apos;great</div><div class="line"> white shark&apos;, </div><div class="line">&apos;tiger</div><div class="line"> shark&apos;,</div><div class="line"></div><div class="line">&apos;hammerhead</div><div class="line">&apos;, </div><div class="line">&apos;electric</div><div class="line"> ray&apos;, </div><div class="line">&apos;stingray</div><div class="line">&apos;, ...]</div></pre></td></tr></table></figure>
<p>Now that we’ve taken care of the labels, let’s dig into thednnmodule of OpenCV 3.3:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># our CNN requires fixed spatial dimensions for our input image(s)</div><div class="line"># so we need to ensure it is resized to 224x224 pixels while</div><div class="line"># performing mean subtraction (104, 117, 123) to normalize the input;</div><div class="line"># after executing this command our &quot;blob&quot; now has the shape:</div><div class="line"># (1, 3, 224, 224)</div><div class="line">blob</div><div class="line"> = cv2.dnn.blobFromImage(image, </div><div class="line">1</div><div class="line">, (</div><div class="line">224</div><div class="line">, </div><div class="line">224</div><div class="line">), (</div><div class="line">104</div><div class="line">, </div><div class="line">117</div><div class="line">, </div><div class="line">123</div><div class="line">))</div></pre></td></tr></table></figure>
<p>Taking note of the comment in the block above, we usecv2.dnn.blobFromImageto perform mean subtraction to normalize the input image which results in a known blob shape (<strong>Line 31</strong>).</p>
<p>We then load our model from disk:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># load our serialized model from disk</div><div class="line"></div><div class="line">print</div><div class="line">(</div><div class="line">&quot;[INFO] loading model...&quot;</div><div class="line">)</div><div class="line">net = cv2.dnn.readNetFromCaffe(</div><div class="line">args</div><div class="line">[</div><div class="line">&quot;prototxt&quot;</div><div class="line">], </div><div class="line">args</div><div class="line">[</div><div class="line">&quot;model&quot;</div><div class="line">])</div></pre></td></tr></table></figure>
<p>Since we’ve opted to use Caffe, we utilizecv2.dnn.readNetFromCaffeto load our Caffe model definitionprototxtand pre-trained modelfrom disk (<strong>Line 35</strong>).</p>
<p>If you are familiar with Caffe, you’ll recognize theprototxtfile as a plain text configuration which follows a JSON-like structure — I recommend that you openbvlc_googlenet.prototxtfrom the_<strong>“Downloads”</strong>_section in a text editor to inspect it.</p>
<p>Note:If you are unfamiliar with configuring Caffe CNNs, then this is a great time to consider thePyImageSearch Gurus course — inside the course you’ll get an in depth look at using deep nets for computer vision and image classification.</p>
<p>Now let’s complete a forward pass through the network withblobas the input:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># </div><div class="line">set</div><div class="line"> the blob as input </div><div class="line">to</div><div class="line"> the network </div><div class="line">and</div><div class="line"> perform a forward-pass </div><div class="line">to</div><div class="line"></div><div class="line"># obtain our output classification</div><div class="line">net.setInput(blob)</div><div class="line">start = </div><div class="line">time</div><div class="line">.</div><div class="line">time</div><div class="line">()</div><div class="line">preds = net.forward()</div><div class="line"></div><div class="line">end</div><div class="line"> = </div><div class="line">time</div><div class="line">.</div><div class="line">time</div><div class="line">()</div><div class="line">print(</div><div class="line">&quot;[INFO] classification took &#123;:.5&#125; seconds&quot;</div><div class="line">.format(</div><div class="line">end</div><div class="line"> - start))</div></pre></td></tr></table></figure>
<p>It is important to note at this step that we aren’t_training_a CNN — rather, we are making use of a pre-trained network. Therefore we are just<em>passing the blob through the network</em>(i.e., forward propagation) to obtain the result (no back-propagation).</p>
<p>First, we specifyblobas our input (<strong>Line 39</strong>). Second, we make astarttimestamp (<strong>Line 40</strong>), followed by passing our input image through the network and storing the predictions. Finally, we set anendtimestamp (<strong>Line 42</strong>) so we can calculate the difference and print the elapsed time (<strong>Line 43</strong>).</p>
<p>Let’s finish up by determining the top five predictions for our input image:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># sort the indexes of the probabilities in descending order (higher</div><div class="line"># probabilitiy first) and grab the top-5 predictions</div><div class="line"></div><div class="line">idxs = np.argsort(preds[</div><div class="line">0</div><div class="line">])[</div><div class="line">::-1</div><div class="line">][</div><div class="line">:5</div><div class="line">]</div></pre></td></tr></table></figure>
<p>Using NumPy, we can easily sort and extract the top five predictions on<strong>Line 47</strong>.</p>
<p>Next, we will display the top five class predictions:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># loop over the top-5 predictions and display them</div><div class="line"></div><div class="line">for (i, idx) in enumerate(idxs):</div><div class="line"> # draw the top prediction on the input image</div><div class="line"> if i == 0:</div><div class="line"> text = &quot;Label: &#123;&#125;, &#123;:.2f&#125;%&quot;.format(classes[idx],</div><div class="line"> preds[</div><div class="line">0</div><div class="line">][</div><div class="line">idx</div><div class="line">] * 100)</div><div class="line"> cv2.putText(image, text, (5, 25),  cv2.FONT</div><div class="line">_HERSHEY_</div><div class="line">SIMPLEX,</div><div class="line"> 0.7, (0, 0, 255), 2)</div><div class="line"> </div><div class="line"> # display the predicted label + associated probability to the</div><div class="line"> # console </div><div class="line"> print(&quot;[INFO] &#123;&#125;. label: &#123;&#125;, probability: &#123;:.5&#125;&quot;.format(i + 1,</div><div class="line"> classes[</div><div class="line">idx</div><div class="line">], preds[</div><div class="line">0</div><div class="line">][</div><div class="line">idx</div><div class="line">]))</div><div class="line"> </div><div class="line"></div><div class="line"># display the output image</div><div class="line"></div><div class="line">cv2.imshow(&quot;Image&quot;, image)</div><div class="line">cv2.waitKey(0)</div></pre></td></tr></table></figure>
<p>The idea for this loop is to (1) draw the top prediction label on the image itself and (2) print the associated class label probabilities to the terminal.</p>
<p>Lastly, we display the image to the screen (<strong>Line 64</strong>) and wait for the user to press a key before exiting (<strong>Line 65</strong>).</p>
<h3 id="Deep-learning-and-OpenCV-classification-results"><a href="#Deep-learning-and-OpenCV-classification-results" class="headerlink" title="Deep learning and OpenCV classification results"></a>Deep learning and OpenCV classification results</h3><p>Now that we have implemented our Python script to utilize deep learning with OpenCV, let’s go ahead and apply it to a few example images.</p>
<p>Make sure you use the_<strong>“Downloads”</strong>_section of this blog post to download the source code + pre-trained GoogLeNet architecture + example images.</p>
<p>From there, open up a terminal and execute the following command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ python deep_learning_with_opencv.py --image images/jemma.png </div><div class="line"> --prototxt bvlc_googlenet.prototxt \</div><div class="line"> --model bvlc_googlenet.caffemodel --labels synset_words.txt</div><div class="line">[INFO] loading model...</div><div class="line">[INFO] classification took </div><div class="line">0.075035</div><div class="line"> seconds</div><div class="line">[INFO] </div><div class="line">1</div><div class="line">. </div><div class="line">label</div><div class="line">: beagle, probability: 0.81137</div><div class="line"></div><div class="line">[INFO] </div><div class="line">2</div><div class="line">. </div><div class="line">label</div><div class="line">: Labrador retriever, probability: 0.031416</div><div class="line"></div><div class="line">[INFO] </div><div class="line">3</div><div class="line">. </div><div class="line">label</div><div class="line">: bluetick, probability: 0.023929</div><div class="line"></div><div class="line">[INFO] </div><div class="line">4</div><div class="line">. </div><div class="line">label</div><div class="line">: EntleBucher, probability: 0.017507</div><div class="line"></div><div class="line">[INFO] </div><div class="line">5</div><div class="line">. </div><div class="line">label</div><div class="line">: Greater Swiss Mountain dog, probability: 0.01444</div></pre></td></tr></table></figure>
<p><img src="http://img1.tuicool.com/IbqeMfm.jpg!web" alt=""></p>
<p>Figure 1:Using OpenCV and deep learning to predict the class label for an input image.</p>
<p>In the above example, we have Jemma, the family beagle. Using OpenCV and GoogLeNet we have correctly classified this image as<em><strong>“beagle”</strong></em>.</p>
<p>Furthermore, inspecting the top-5 results we can see that the other top predictions are also relevant, all of them of which are dogs that have similar physical appearances as beagles.</p>
<p>Taking a look at the timing we also see that the forward pass took &lt; 1 second, even though we are using our CPU.</p>
<p>Keep in mind that the forward pass is substantially faster than the backward pass as we do not need to compute the gradient and backpropagate through the network.</p>
<p>Let’s classify another image using OpenCV and deep learning:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ python deep_learning_with_opencv.py --image images/traffic_light.png </div><div class="line"> --prototxt bvlc_googlenet.prototxt \</div><div class="line"> --model bvlc_googlenet.caffemodel --labels synset_words.txt</div><div class="line">[INFO] loading model...</div><div class="line">[INFO] classification took </div><div class="line">0.080521</div><div class="line"> seconds</div><div class="line">[INFO] </div><div class="line">1</div><div class="line">. </div><div class="line">label</div><div class="line">: traffic light, probability: 1.0</div><div class="line"></div><div class="line">[INFO] </div><div class="line">2</div><div class="line">. </div><div class="line">label</div><div class="line">: pole, probability: 4.9961e-07</div><div class="line"></div><div class="line">[INFO] </div><div class="line">3</div><div class="line">. </div><div class="line">label</div><div class="line">: spotlight, probability: 3.4974e-08</div><div class="line"></div><div class="line">[INFO] </div><div class="line">4</div><div class="line">. </div><div class="line">label</div><div class="line">: street sign, probability: 3.3623e-08</div><div class="line"></div><div class="line">[INFO] </div><div class="line">5</div><div class="line">. </div><div class="line">label</div><div class="line">: loudspeaker, probability: 2.0235e-08</div></pre></td></tr></table></figure>
<p><img src="http://img0.tuicool.com/zYry2qi.jpg!web" alt=""></p>
<p>Figure 2:OpenCV and deep learning is used to correctly label this image as “traffic light”.</p>
<p>OpenCV and GoogLeNet correctly label this image as_<strong>“traffic light”</strong>_with 100% certainty.</p>
<p>In this example we have a<em><strong>“bald eagle”</strong></em>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ python deep_learning_with_opencv.py --image images/eagle.png</div><div class="line"> --prototxt bvlc_googlenet.prototxt \</div><div class="line"> --model bvlc_googlenet.caffemodel --labels synset_words.txt</div><div class="line">[INFO] loading model...</div><div class="line">[INFO] classification took </div><div class="line">0.087207</div><div class="line"> seconds</div><div class="line">[INFO] </div><div class="line">1</div><div class="line">. </div><div class="line">label</div><div class="line">: bald eagle, probability: 0.96768</div><div class="line"></div><div class="line">[INFO] </div><div class="line">2</div><div class="line">. </div><div class="line">label</div><div class="line">: kite, probability: 0.031964</div><div class="line"></div><div class="line">[INFO] </div><div class="line">3</div><div class="line">. </div><div class="line">label</div><div class="line">: vulture, probability: 0.00023595</div><div class="line"></div><div class="line">[INFO] </div><div class="line">4</div><div class="line">. </div><div class="line">label</div><div class="line">: albatross, probability: 6.3653e-05</div><div class="line"></div><div class="line">[INFO] </div><div class="line">5</div><div class="line">. </div><div class="line">label</div><div class="line">: black grouse, probability: 1.6147e-05</div></pre></td></tr></table></figure>
<p><img src="http://img0.tuicool.com/nI3eiiF.jpg!web" alt=""></p>
<p>Figure 3:The “deep neural network” (dnn) module inside OpenCV 3.3 can be used to classify images using pre-trained models.</p>
<p>We are once again able to correctly classify the input image.</p>
<p>Our final example is a<em><strong>“vending machine”</strong></em>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ python deep_learning_with_opencv.py --image images/vending_machine.png</div><div class="line"> --prototxt bvlc_googlenet.prototxt \</div><div class="line"> --model bvlc_googlenet.caffemodel --labels synset_words.txt</div><div class="line">[INFO] loading model...</div><div class="line">[INFO] classification took </div><div class="line">0.099602</div><div class="line"> seconds</div><div class="line">[INFO] </div><div class="line">1</div><div class="line">. </div><div class="line">label</div><div class="line">: vending machine, probability: 0.99269</div><div class="line"></div><div class="line">[INFO] </div><div class="line">2</div><div class="line">. </div><div class="line">label</div><div class="line">: cash machine, probability: 0.0023691</div><div class="line"></div><div class="line">[INFO] </div><div class="line">3</div><div class="line">. </div><div class="line">label</div><div class="line">: pay-phone, probability: 0.00097005</div><div class="line"></div><div class="line">[INFO] </div><div class="line">4</div><div class="line">. </div><div class="line">label</div><div class="line">: ashcan, probability: 0.00092097</div><div class="line"></div><div class="line">[INFO] </div><div class="line">5</div><div class="line">. </div><div class="line">label</div><div class="line">: mailbox, probability: 0.00061188</div></pre></td></tr></table></figure>
<p><img src="http://img0.tuicool.com/6jyaeyu.jpg!web" alt=""></p>
<p>Figure 4:Since our GoogLeNet model is pre-trained on ImageNet, we can classify each of the 1,000 labels inside the dataset using OpenCV + deep learning.</p>
<p>OpenCV + deep learning once again correctly classifes the image.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In today’s blog post we learned how to use OpenCV for deep learning.</p>
<p>With the release of OpenCV 3.3 the deep neural network (dnn) library has been substantially overhauled, allowing us to load pre-trained networks via the Caffe, TensorFlow, and Torch/PyTorch frameworks and then use them to classify input images.</p>
<p>I imagine Keras support will also be coming soon, given how popular the framework is. This will likely take be a non-trivial implementation as Keras itself can support multiple numeric computation backends.</p>
<p>Over the next few weeks we’ll:</p>
<ol>
<li>Take a deeper dive into the<br>dnn<br>  module and how it can be used inside our Python + OpenCV scripts.</li>
<li>Learn how to modify Caffe<br>.prototxt<br>  files to be compatible with OpenCV.</li>
<li>Discover how we can apply deep learning using OpenCV to the Raspberry Pi.</li>
</ol>
<p><em>This is a can’t-miss series of blog posts</em>, so be before you go,<em>make sure you enter your email address in the form below to be notified when these posts go live!</em></p>
<p>Source: <a href="http://www.tuicool.com/articles/hit/qY3QR32">http://www.pyimagesearch.com/2017/08/21/deep-learning-with-opencv/</a></p>

  </div>
  

 <!-- jsSocials -->
<script src="/jssocials-1.4.0/jssocials.min.js"></script>
<link rel="stylesheet" href="/jssocials-1.4.0/jssocials.css">
<link rel="stylesheet" href="/jssocials-1.4.0/jssocials-theme-flat.css">

<div class="socials-share-btn"></div>
<script>
  if ($) {
    $(document).ready(function(){
      $(".socials-share-btn").jsSocials({
        shares: ["email", "twitter", "facebook", "googleplus", "linkedin", "pinterest", "stumbleupon", "whatsapp"]
      });
    })
  }
</script>


  
<section id="comments">
  <div id="disqus_thread"></div>
</section>
<script>
  var disqus_shortname = 'gmagon';
  var disqus_url = 'https://gmagon.com/blog/2017/08/22/opencv-33-supports-several-deep-learning-frameworks/index.html';
  var disqus_title = "OpenCV 3.3 Supports Several Deep Learning Frameworks";
  var disqus_config = function(){
    this.language = 'en';
  };
  (function(){
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  <script src="/js/audios.js"></script>
</article>

          </div>
      
          <aside id="article-toc" role="navigation">
                <div id="article-toc-inner">
                  <strong class="sidebar-title">Contents</strong>
                  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Learning-with-OpenCV"><span class="toc-text">Deep Learning with OpenCV</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Learning-inside-OpenCV-3-3"><span class="toc-text">Deep Learning inside OpenCV 3.3</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Configure-your-machine-with-OpenCV-3-3"><span class="toc-text">Configure your machine with OpenCV 3.3</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#OpenCV-deep-learning-functions-and-frameworks"><span class="toc-text">OpenCV deep learning functions and frameworks</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Classifying-images-using-deep-learning-and-OpenCV"><span class="toc-text">Classifying images using deep learning and OpenCV</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-learning-and-OpenCV-classification-results"><span class="toc-text">Deep learning and OpenCV classification results</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-text">Summary</span></a></li></ol>
                  <a href="#" id="article-toc-top">Back to Top</a>
                </div>
          </aside>
        </div>
      </article>
    </div>
  </div>
</div>

<div class="class-content-wrap">
  <div class="inner">
    <div class="inner-wrap landing-bunting">
      <div class="intro-sub-content-wrap">
      </div>
    </div>
  </div>
</div>



    <footer id="footer" class="landing-bunting font-e3">
  <div class="inner">
    <div id="footer-some-docs">
        <a href="/terms_conditions.html" class="footer-doc-link" >Terms & Conditions</a>
        <a href="/privacy.html" class="footer-doc-link" >Privacy</a>
        <a href="/end-user-license-agreement.html" class="footer-doc-link" >License Agreement</a>
    </div>
    <div id="footer-copyright">
       <a href="" > Copyright &copy; 2017 Gmagon,Inc. All rights reserved. </a>
    </div>
  </div>

  <div class="inner">
    <div id="footer-links">
        
        <a href="https://twitter.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-twitter"></i></a>
        
        <a href="https://www.facebook.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-facebook"></i></a>
        <a href="https://www.youtube.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-youtube"></i></a>
        <a href="https://www.instagram.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-instagram"></i></a>
    </div>
  </div>


  <div class="inner">
    <div id="footer-security">
       <p>
          <img src="/asset/images/security/klogo.png">
          <img src="/asset/images/security/mcafee.png">
          <img src="/asset/images/security/cmmodo_scanned.png">
          <img src="/asset/images/security/softonic_tested.png">
          <img src="/asset/images/security/tested_by_sucuri.png">
          <img src="/asset/images/security/norton.png">
          <img src="/asset/images/security/eset_logo.png">
       </p>
    </div>
  </div>




</footer>

  </div>
  <div id="mobile-nav-dimmer"></div>
  <nav id="mobile-nav">
  <div id="mobile-nav-inner">
    <ul id="mobile-nav-list">
      <a href="/" class="mobile-nav-link ">Home</a><a href="/products/" class="mobile-nav-link ">Products</a><a href="/guide/" class="mobile-nav-link ">Guide</a><a href="/support/" class="mobile-nav-link ">Support</a><a href="/blog/" class="mobile-nav-link ">Blog</a>
      
    </ul>
    
  </div>
  <div id="mobile-lang-select-wrap">
    <span id="mobile-lang-select-label"><i class="fa fa-globe"></i><span>English</span></span>
    <select id="mobile-lang-select" data-canonical="">
      
        <option value="en" selected>English</option>
      
    </select>
  </div>
</nav>

  <!-- Scripts -->
<script src="/build/js/main-8277743eaa.js"></script>
<!-- <script src="https://cdn.jsdelivr.net/retinajs/1.3.0/retina.min.js" async></script> -->

<!-- totop -->
<div id="gmagon_totop" style="position:fixed;bottom:150px;right:30px;cursor: pointer;">
  <a title="Back to top"><img src="/asset/images/scroll-up.png"/></a>
</div>
<script src="/js/totop.js"></script>





<!-- Google Analytics -->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-99314951-1', 'auto');
  ga('send', 'pageview');
</script>


</body>
</html>