<!DOCTYPE html>
<html lang="en">
<head prefix="og: http://ogp.me/ns#">
  <meta charset="utf-8">

  <title>Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.</title>

  <meta http-equiv="X-UA-Compatible" content="IE=8; IE=9; IE=Edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta name="robots" content="noodp" />
  <meta name="keywords" content="Generative Long Short-Term Memory Networks" />
  <meta name="description" content="Generative Long Short-Term Memory Networks" />

  <!-- Custom config og:image -->


  <!-- Open Graph -->
<meta name="description" content="Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:type" content="apps">
<meta property="og:title" content="Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:url" content="https://gmagon.com/blog/2017/08/25/generative-long-short-term-memory-networks/index.html">
<meta property="og:site_name" content="Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:description" content="Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://img2.tuicool.com/q6NNrmV.jpg!web">
<meta property="og:image" content="http://img2.tuicool.com/qyyAbq6.png!web">
<meta property="og:image" content="http://img0.tuicool.com/IVRRbmq.png!web">
<meta property="og:image" content="http://img1.tuicool.com/qE73Q3A.png!web">
<meta property="og:updated_time" content="2017-08-25T08:28:07.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.">
<meta name="twitter:description" content="Generative Long Short-Term Memory Networks - Gmagon Software - handy and professional Mac apps.">
<meta name="twitter:image" content="http://img2.tuicool.com/q6NNrmV.jpg!web">
<meta name="twitter:site" content="gmagonshare">
<meta property="fb:admins" content="432634277117208">
<meat name="twitter:url" content="https://gmagon.com/blog/2017/08/25/generative-long-short-term-memory-networks/index.html">



  <!-- algolia_config -->
  
  
  <!-- Canonical links -->
  <link rel="canonical" href="https://gmagon.com/blog/2017/08/25/generative-long-short-term-memory-networks/index.html">

  <!-- Alternative links -->
  

  <!-- Icon -->
  <link rel="apple-touch-icon" sizes="57x57" href="/icon/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icon/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icon/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icon/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icon/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icon/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icon/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icon/apple-touch-icon-152x152.png">
  <link rel="icon" type="image/png" href="/icon/favicon-196x196.png" sizes="196x196">
  <link rel="icon" type="image/png" href="/icon/favicon-160x160.png" sizes="160x160">
  <link rel="icon" type="image/png" href="/icon/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/icon/favicon-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="/icon/favicon-32x32.png" sizes="32x32">
  <meta name="msapplication-TileColor" content="#2f83cd">
  <meta name="msapplication-TileImage" content="/icon/mstile-144x144.png">

  <!-- CSS -->
  <link rel="stylesheet" href="/build/css/navy-6ac2b4c9e5.css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  
  <!-- jQuery -->
  <script src="/js/jquery/jquery-3.2.1.min.js"></script>
<script src="/js/jquery/jquery-migrate-1.4.1.min.js"></script>



  <!-- ForPostLayout -->
  
    
    
  
  <!-- endForPostLayout -->

  <!-- RSS -->
  <link rel="alternate" href="/atom.xml" title="Gmagon Software - handy and professional Mac apps.">

  <!-- algolia_search -->
  <script src="/assets/algolia/algoliasearchLite.min.js" async></script>

  <!-- Github Button -->
  <script async defer src="https://buttons.github.io/buttons.js"></script>

  <!-- Utils -->
<script src="/js/utils.js"></script>
</head>

<body>
  <div id="container">
    <header id="header">
  <div class="wrapper">
    <div id="header-inner" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Gmagon Software - handy and professional Mac apps.</a>
        <span>gmagon </span>
      </h1>
      <nav id="main-nav">
        <a href="/" class="main-nav-link ">Home</a><a href="/products/" class="main-nav-link ">Products</a><a href="/guide/" class="main-nav-link ">Guide</a><a href="/support/" class="main-nav-link ">Support</a><a href="/blog/" class="main-nav-link ">Blog</a>
        <div id="search-input-wrap">
          <a href="/search/" class="text-decoration-none">
            <div id="search-input-icon">
              <i class="fa fa-search"></i>
            </div>
          </a>
        </div>
      </nav>
      <div id="lang-select-wrap">
        <label id="lang-select-label"><i class="fa fa-globe"></i><span>English</span></label>
        <select id="lang-select" data-canonical="">
          
            <option value="en" selected>English</option>
          
        </select>
      </div>
      <a id="mobile-nav-toggle">
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
      </a>
    </div>
  </div>  
</header>
<div class="hide-wrap-head-top"></div>

    <div class="class-content-wrap">
  <div class="inner">
    <div class="inner-wrap fill-bunting font-e3">
      <h2 id="banner-title"> Generative Long Short-Term Memory Networks </h2>
      <div id="banner-start">
        <a class="btn btn-static-secondary btn-shadow" href="https://gitter.im/Gmagon/support" ttarget="_blank" rel="nofollow me noopener noreferrer" >Need help?</a>
      </div>
    </div>
  </div>
</div>

<div class="class-content-wrap">
  <div class="wrapper">
    <div class="inner">
      <article class="article-container" itemscope itemtype="http://schema.org/Article">
        <div class="article-inner">
          <div class="article">
          <div class="hide-wrap-head-top"></div>
<article class="article post" itemscope itemtype="http://schema.org/Article">
  <header class="article-header">
    
      <h1 class="article-title" itemprop="name">Generative Long Short-Term Memory Networks</h1>
    
    <a href="/blog/2017/08/25/generative-long-short-term-memory-networks/" class="article-date"><time datetime="2017-08-25T00:00:00.000Z">2017-08-25</time></a>
  </header>
  <div class="article-content" itemprop="articleBody">
    <p>The Long Short-Term Memory recurrent neural network was developed for sequence prediction.</p>
<p>In addition to sequence prediction problems. LSTMs can also be used as a generative model</p>
<p>In this post, you will discover how LSTMs can be used as generative models.</p>
<p>After completing this post, you will know:</p>
<ul>
<li>About generative models, with a focus on generative models for text called language modeling.</li>
<li>Examples of applications where LSTM Generative models have been used.</li>
<li>Examples of how to model text for generative models with LSTMs.</li>
</ul>
<p>Let’s get started.</p>
<p><img src="http://img2.tuicool.com/q6NNrmV.jpg!web" alt=""></p>
<p>Gentle Introduction to Generative Long Short-Term Memory Networks</p>
<p>Photo by<a href="https://www.flickr.com/photos/73014677@N05/10035345914/">Fraser Mummery</a>, some rights reserved.</p>
<h3 id="Need-help-with-LSTMs-for-Sequence-Prediction"><a href="#Need-help-with-LSTMs-for-Sequence-Prediction" class="headerlink" title="Need help with LSTMs for Sequence Prediction?"></a>Need help with LSTMs for Sequence Prediction?</h3><p>Take my free 7-day email course and discover 6 different LSTM architectures (with sample code).</p>
<p>Click to sign-up and also get a free PDF Ebook version of the course.</p>
<p><a href="https://machinelearningmastery.lpages.co/leadbox/1403a9373f72a2%3A164f8be4f346dc/5754903989321728/">Start Your FREE Mini-Course Now!</a></p>
<h2 id="Generative-Models"><a href="#Generative-Models" class="headerlink" title="Generative Models"></a>Generative Models</h2><p>LSTMs can be used as a generative model.</p>
<p>Given a large corpus of sequence data, such as text documents, LSTM models can be designed to learn the general structural properties of the corpus, and when given a seed input, can generate new sequences that are representative of the original corpus.</p>
<p>The problem of developing a model to generalize a corpus of text is called language modeling in the field of natural language processing. A language model may work at the word level and learn the probabilistic relationships between words in a document in order to accurately complete a sentence and generate entirely new sentences. At its most challenging, language models work at the character level, learning from sequences of characters, and generating new sequences one character at a time.</p>
<p>The goal of character-level language modeling is to predict the next character in a sequence.</p>
<p>—<a href="http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf">Generating Text with Recurrent Neural Networks</a>, 2011.</p>
<p>Although more challenging, the added flexibility of a character-level model allows new words to be generated, punctuation added, and the generation of any other structures that may exist in the text data.</p>
<p>… predicting one character at a time is more interesting from the perspective of sequence generation, because it allows the network to invent novel words and strings.</p>
<p>—<a href="https://arxiv.org/abs/1308.0850">Generating Sequences With Recurrent Neural Networks</a>, 2013.</p>
<p>Language modeling is by far the most studied application of Generative LSTMs, perhaps because of the use of standard datasets where model performance can be quantified and compared. This approach has been used to generate text on a suite of interesting language modeling problems, such as:</p>
<ul>
<li>Generating Wikipedia articles (including markup).</li>
<li>Generating snippets from great authors like Shakespeare.</li>
<li>Generating technical manuscripts (including markup).</li>
<li>Generating computer source code.</li>
<li>Generating article headlines.</li>
</ul>
<p>The quality of the results vary; for example, the markup or source code may require manual intervention to render or compile. Nevertheless, the results are impressive.</p>
<p>The approach has also been applied to different domains where a large corpus of existing sequence information is available and new sequences can be generated one step at a time, such as:</p>
<ul>
<li>Handwriting generation.</li>
<li>Music generation.</li>
<li>Speech generation.</li>
</ul>
<p><img src="http://img2.tuicool.com/qyyAbq6.png!web" alt=""></p>
<p>Example of LSTMs used in Automatic Handwriting Generation.</p>
<p>Taken from “<a href="https://arxiv.org/abs/1308.0850">Generating Sequences With Recurrent Neural Networks</a>“, 2014.</p>
<h2 id="Generative-LSTMs"><a href="#Generative-LSTMs" class="headerlink" title="Generative LSTMs"></a>Generative LSTMs</h2><p>A Generative LSTM is not really architecture, it is more a change in perspective about what an LSTM predictive model learns and how the model is used.</p>
<p>We could conceivably use any LSTM architecture as a generative model. In this case, we will use a simple Vanilla LSTM.</p>
<p><img src="http://img0.tuicool.com/IVRRbmq.png!web" alt=""></p>
<p>Vanilla LSTM Architecture for Generative Models</p>
<p>In the case of a character-level language model, the alphabet of all possible characters is fixed. A one hot encoding is used both for learning input sequences and predicting output sequences.</p>
<p>A one-to-one model is used where one step is predicted for each input time step. This means that input sequences may require specialized handling in order to be vectorized or formatted for efficiently training a supervised model.</p>
<p>For example, given the sequence:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&quot;hello world&quot;</div></pre></td></tr></table></figure>
<p>A dataset would need to be constructed such as:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&apos;h&apos; =&gt; &apos;e&apos;</div><div class="line">&apos;e&apos; =&gt; &apos;l&apos;</div><div class="line">&apos;l&apos; =&gt; &apos;l&apos;</div><div class="line">...</div></pre></td></tr></table></figure>
<p>This could be presented as-is as a dataset of one time step samples, which could be quite limiting to the network (e.g. no BPTT).</p>
<p>Alternately, it could be vectorized to a fixed-length input sequence for a many-to-one time step model, such as:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[&apos;h&apos;, &apos;e&apos;, &apos;l&apos;] =&gt; &apos;l&apos;</div><div class="line">[&apos;e&apos;, &apos;l&apos;, &apos;l&apos;] =&gt; &apos;o&apos;</div><div class="line">[&apos;l&apos;, &apos;l&apos;, &apos;o&apos;] =&gt; &apos; &apos;</div><div class="line">...</div></pre></td></tr></table></figure>
<p>Or, a fixed-length output sequence for a one-to-many time step model:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&apos;h&apos; =&gt; [&apos;e&apos;, &apos;l&apos;, &apos;l&apos;]</div><div class="line">&apos;e&apos; =&gt; [&apos;l&apos;, &apos;l&apos;, &apos;o&apos;]</div><div class="line">&apos;l&apos; =&gt; [&apos;l&apos;, &apos;o&apos;, &apos; &apos;]</div><div class="line">...</div></pre></td></tr></table></figure>
<p>Or some variation on these approaches.</p>
<p>Note that the same vectorized representation would be required when making predictions, meaning that predicted characters would need to be presented as input for subsequent samples. This could be quite clumsy in implementation.</p>
<p>The internal state of the network may need careful management, perhaps reset at choice locations in the input sequence (e.g. end of paragraph, page, or chapter) rather than at the end of each input sequence.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this post, you discovered the use of LSTMs as generative models.</p>
<p>Specifically, you learned:</p>
<ul>
<li>About generative models, with a focus on generative models for text called language modeling.</li>
<li>Examples of applications where LSTM Generative models have been used.</li>
<li>Examples of how to model text for generative models with LSTMs.</li>
</ul>
<p>Do you have any questions?</p>
<p>Ask your questions in the comments below and I will do my best to answer.</p>
<h2 id="Develop-LSTMs-for-Sequence-Prediction-Today"><a href="#Develop-LSTMs-for-Sequence-Prediction-Today" class="headerlink" title="Develop LSTMs for Sequence Prediction Today!"></a>Develop LSTMs for Sequence Prediction Today!</h2><p><img src="http://img1.tuicool.com/qE73Q3A.png!web" alt=""></p>
<h4 id="Develop-Your-Own-LSTM-models-in-Minutes"><a href="#Develop-Your-Own-LSTM-models-in-Minutes" class="headerlink" title="Develop Your Own LSTM models in Minutes"></a>Develop Your Own LSTM models in Minutes</h4><p>…with just a few lines of python code</p>
<p>Discover how in my new Ebook:</p>
<p><a href="https://machinelearningmastery.com/lstms-with-python/">Long Short-Term Memory Networks with Python</a></p>
<p>It provides<strong>self-study tutorials</strong>on topics like:</p>
<p>_CNN LSTMs, Encoder-Decoder LSTMs, generative models, data preparation, making predictions_and much more…</p>
<p>Finally Bring LSTM Recurrent Neural Networks to</p>
<p>Your Sequence Predictions Projects</p>
<p>Skip the Academics. Just Results.</p>
<p>Source: <a href="http://www.tuicool.com/articles/hit/2auUFfA">https://machinelearningmastery.com/gentle-introduction-generative-long-short-term-memory-networks/</a></p>

  </div>
  

 <!-- jsSocials -->
<script src="/jssocials-1.4.0/jssocials.min.js"></script>
<link rel="stylesheet" href="/jssocials-1.4.0/jssocials.css">
<link rel="stylesheet" href="/jssocials-1.4.0/jssocials-theme-flat.css">

<div class="socials-share-btn"></div>
<script>
  if ($) {
    $(document).ready(function(){
      $(".socials-share-btn").jsSocials({
        shares: ["email", "twitter", "facebook", "googleplus", "linkedin", "pinterest", "stumbleupon", "whatsapp"]
      });
    })
  }
</script>


  
<section id="comments">
  <div id="disqus_thread"></div>
</section>
<script>
  var disqus_shortname = 'gmagon';
  var disqus_url = 'https://gmagon.com/blog/2017/08/25/generative-long-short-term-memory-networks/index.html';
  var disqus_title = "Generative Long Short-Term Memory Networks";
  var disqus_config = function(){
    this.language = 'en';
  };
  (function(){
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  <script src="/js/audios.js"></script>
</article>

          </div>
      
          <aside id="article-toc" role="navigation">
                <div id="article-toc-inner">
                  <strong class="sidebar-title">Contents</strong>
                  <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Need-help-with-LSTMs-for-Sequence-Prediction"><span class="toc-text">Need help with LSTMs for Sequence Prediction?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generative-Models"><span class="toc-text">Generative Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generative-LSTMs"><span class="toc-text">Generative LSTMs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-text">Summary</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Develop-LSTMs-for-Sequence-Prediction-Today"><span class="toc-text">Develop LSTMs for Sequence Prediction Today!</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Develop-Your-Own-LSTM-models-in-Minutes"><span class="toc-text">Develop Your Own LSTM models in Minutes</span></a></li></ol></li></ol>
                  <a href="#" id="article-toc-top">Back to Top</a>
                </div>
          </aside>
        </div>
      </article>
    </div>
  </div>
</div>

<div class="class-content-wrap">
  <div class="inner">
    <div class="inner-wrap landing-bunting">
      <div class="intro-sub-content-wrap">
      </div>
    </div>
  </div>
</div>



    <footer id="footer" class="landing-bunting font-e3">
  <div class="inner">
    <div id="footer-some-docs">
        <a href="/terms_conditions.html" class="footer-doc-link" >Terms & Conditions</a>
        <a href="/privacy.html" class="footer-doc-link" >Privacy</a>
        <a href="/end-user-license-agreement.html" class="footer-doc-link" >License Agreement</a>
    </div>
    <div id="footer-copyright">
       <a href="" > Copyright &copy; 2017 Gmagon,Inc. All rights reserved. </a>
    </div>
    <div id="footer-links">
      
      <a href="https://twitter.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-twitter"></i></a>
      
      <a href="https://www.facebook.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-facebook"></i></a>
      <a href="https://www.youtube.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-youtube"></i></a>
      <a href="https://www.instagram.com/gmagonshare" class="footer-link" target="_blank" rel="nofollow me noopener noreferrer" ><i class="fa fa-instagram"></i></a>
    </div>
  </div>
</footer>

  </div>
  <div id="mobile-nav-dimmer"></div>
  <nav id="mobile-nav">
  <div id="mobile-nav-inner">
    <ul id="mobile-nav-list">
      <a href="/" class="mobile-nav-link ">Home</a><a href="/products/" class="mobile-nav-link ">Products</a><a href="/guide/" class="mobile-nav-link ">Guide</a><a href="/support/" class="mobile-nav-link ">Support</a><a href="/blog/" class="mobile-nav-link ">Blog</a>
      
    </ul>
    
  </div>
  <div id="mobile-lang-select-wrap">
    <span id="mobile-lang-select-label"><i class="fa fa-globe"></i><span>English</span></span>
    <select id="mobile-lang-select" data-canonical="">
      
        <option value="en" selected>English</option>
      
    </select>
  </div>
</nav>

  <!-- Scripts -->
<script src="/build/js/main-8277743eaa.js"></script>
<!-- <script src="https://cdn.jsdelivr.net/retinajs/1.3.0/retina.min.js" async></script> -->

<!-- totop -->
<div id="gmagon_totop" style="position:fixed;bottom:150px;right:30px;cursor: pointer;">
  <a title="Back to top"><img src="/asset/images/scroll-up.png"/></a>
</div>
<script src="/js/totop.js"></script>





<!-- Google Analytics -->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-99314951-1', 'auto');
  ga('send', 'pageview');
</script>


</body>
</html>